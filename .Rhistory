list = FALSE)
training <-H4A[inTrain,]
# no longer needed !
#testing <-H4A[-inTrain,]
#testrecs<-as.numeric(rownames(testing)) # row(testing)[,1]
H4A.R <-lda(as.matrix(H4A[,c(2:72)]), H4A[,"PopSex"], data = HA4, prior = c(0.25,0.25,0.25,0.25), subset = -inTrain, CV = T)
Accuracies[i] <-confusionMatrix(H4A[-inTrain,"PopSex"], H4A.R$class)$overall["Accuracy"]
}
summary(Accuracies)
#  Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
# 0.07937 0.20635 0.25397 0.25021 0.28571 0.44444
plot(density(Accuracies))
library(class) #k-nearest neighbors
library(kknn) #weighted k-nearest neighbors
library(e1071) #SVM
library(caret) #select tuning parameters
library(MASS) # contains the data
library(reshape2) #assist in creating boxplots
library(ggplot2) #create boxplots
library(kernlab) #assist with SVM feature selection
library(pROC)
install.packages("kknn")
library(class) #k-nearest neighbors
library(kknn) #weighted k-nearest neighbors
library(e1071) #SVM
library(caret) #select tuning parameters
library(MASS) # contains the data
library(reshape2) #assist in creating boxplots
library(ggplot2) #create boxplots
library(kernlab) #assist with SVM feature selection
library(pROC)
install.packages("pROC")
library(class) #k-nearest neighbors
library(kknn) #weighted k-nearest neighbors
library(e1071) #SVM
library(caret) #select tuning parameters
library(MASS) # contains the data
library(reshape2) #assist in creating boxplots
library(ggplot2) #create boxplots
library(kernlab) #assist with SVM feature selection
library(pROC)
set.seed(7); #replicable across our PCs?
sahdd <-
read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/sahdd.csv',
as.is = T);
sahdd$chd <- as.factor(sahdd$chd)
SS <- cbind(sahdd[,c(1,11)], scale(sahdd[,c(-1,-6,-11)]) )
str(SS)
inTrain <- createDataPartition(y = SS$chd, # y = grouping variable,
stratified random split
p = .70, ## The proportion of records in the training set
list = FALSE)
train <- SS[inTrain,]
test <- SS[-inTrain,]
# ERRORS - book code, demo code from e1071 will not run
#linear.tune = tune.svm(chd~., data=train, kernel="linear",
cost=c(0.001, 0.01, 0.1, 1,5,10))
#poly.tune = tune.svm(chd~., data=train, kern
inTrain <- createDataPartition(y = SS$chd, # y = grouping variable,
stratified random split
p = .70, ## The proportion of records in the training set
list = FALSE)
inTrain <- createDataPartition(y = SS$chd, stratified random split p = .70, list = FALSE)
inTrain <- createDataPartition(y = SS$chd, stratified random = split p = .70, list = FALSE)
inTrain <- createDataPartition(y = SS$chd,  p = .70, list = FALSE)
train <- SS[inTrain,]
test <- SS[-inTrain,]
cost=c(0.001, 0.01, 0.1, 1,5,10))
cost=c(0.001, 0.01, 0.1, 1,5,10)
SS.ksvm <- ksvm(chd ~ .,
data=train,
kernel="rbfdot",
prob.model=TRUE )
SS.ksvm
cost=c(0.001, 0.01, 0.1, 1,5,10)
confusionMatrix(test$chd, predict(SS.ksvm, test) )
install.packages("rattle")
library("rattle")
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(5))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
pda4 <- train(PopSex ~ ., data = training, method = "QdaCov",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.k = 3))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
warining()
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(5))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
pda4 <- train(PopSex ~ ., data = training, method = "QdaCov",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.k = 3))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
Hef <-  read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/HefM.csv', as.is = T);
str(Hef)
HefNB <- na.omit(Hef)
Accuracies <- c(0.00)
for (i in seq(20)) # only 20 because it takes a while
{
inTrain <- createDataPartition(y = HefNB$Pop, # y = grouping variable,
stratified random split
p = .70, ## The proportion of records in the training set
list = FALSE)
train <- HefNB[inTrain,]
test <- HefNB[-inTrain,]
nb2 <- train(Pop ~ ANS+INA+IOB+NAW+NBS+NO+PBD+ZS, data = train, method
= "nb",
trControl = ctrl,
tuneGrid = data.frame(usekernel = TRUE, fL = 0.5, adjust
= 5))
bps2 <- predict(nb2, newdata = test)
Accuracies[i] <- confusionMatrix(test$Pop,bps2)$overall["Accuracy"]
}
summary(Accuracies)
Accuracies <- c(0.00)
for (i in seq(20)) # only 20 because it takes a while
{
inTrain <- createDataPartition(y = HefNB$Pop, # y = grouping variable,
stratified random split
p = .70, ## The proportion of records in the training set
list = FALSE)
train <- HefNB[inTrain,]
test <- HefNB[-inTrain,]
nb2 <- train(Pop ~ ANS+INA+IOB+NAW+NBS+NO+PBD+ZS, data = train, method = "nb",
trControl = ctrl,
tuneGrid = data.frame(usekernel = TRUE, fL = 0.5, adjust
= 5))
bps2 <- predict(nb2, newdata = test)
Accura
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(5))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
pda4 <- train(PopSex ~ ., data = training, method = "multinom",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.k = 3))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
pda4
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(5))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
pda4 <- train(PopSex ~ ., data = training, method = "multinom",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.decay = 3))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]}
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(2))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
pda4 <- train(PopSex ~ ., data = training, method = "multinom",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.decay = 3))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(2))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
pda4 <- train(PopSex ~ ., data = training, method = "pda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.lamda = 3))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]}
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(2))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
pda4 <- train(PopSex ~ ., data = training, method = "pda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.lambda = 3))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(2))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
pda4 <- train(PopSex ~ ., data = training, method = "pda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.lambda = 0))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(2))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
pda4 <- train(PopSex ~ ., data = training, method = "pda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.lambda = 1))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(2))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
pda4 <- train(PopSex ~ ., data = training, method = "pda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.lambda = 2))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(5))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
pda4 <- train(PopSex ~ ., data = training, method = "pda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.lambda = 3))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
Accuracies <- c(0.00)
for (i in seq(5))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
pda4 <- train(PopSex ~ ., data = training, method = "pda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.lambda = 3))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(pda4_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
Accuracies <- c(0.00)
for (i in seq(5))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
pda4 <- train(PopSex ~ ., data = training, method = "pda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.lambda = 0))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(pda4_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(500))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
pda4 <- train(PopSex ~ ., data = training, method = "pda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.lambda = 2))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(pda4_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
plot(density(Accuracies))
pda4
confusionMatrix(pda4_pred,testing$PopSex)
confusionMatrix(pda4)
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(5))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
pda4 <- train(PopSex ~ ., data = training, method = "pda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.lambda = 2))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(pda4_pred,testing$PopSex)$overall["Accuracy"]
}
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(5))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
pda4 <- train(PopSex ~ ., data = training, method = "pda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.lambda = 2))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(pda4_pred,testing$PopSex)$overall["Accuracy"]
}
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
setwd("C:/Users/Nucleus/Desktop/Project/Advance-Analytical-Technique")
altcrime<-read.csv(altcrime.csv)
altcrime<-read.csv("altcrime.csv")
head(altcrime)
plot(as.factor(altcrime$crime)), altcrime$beat)
head(altcrime)
plot(altcrime$crime, altcrime$beat)
plot(altcrime$crime, altcrime$neighborhood)
unique(altcrime$crime)
table
table(altcrime$crime)
plot(table(altcrime$crime))
#Load libraries,
require(ggplot2)
require(animation)
require(dplyr)
#Load data
edeaths <- read.csv('altcrime.csv')
#Load the map data, set color value to -1
s = map_data('world')
install.packages("maps")
#Load libraries,
require(ggplot2)
require(animation)
require(dplyr)
#Load data
edeaths <- read.csv('altcrime.csv')
#Load the map data, set color value to -1
s = map_data('world')
s
s$colour = -1
require(ggplot2)
require(animation)
require(dplyr)
install.packages("animation")
require(ggplot2)
require(animation)
require(dplyr)
#Load data
altcrime <- read.csv('altcrime.csv')
#Load the map data, set color value to -1
s = map_data('world')
s$colour = -1
head(altcrime)
#Load data
altcrime <- read.csv('altcrime.csv')
#Load the map data, set color value to -1
s = map_data('world')
s$colour = -1
#malaria estimated  deaths
#create a list of years for use in both plots
years <- altcrime$date
head(years)
saveGIF(
for (yr in years ){
print(yr)
altcrime<-read.csv("altcrimev1.csv")
head(altcrime)
plot(altcrime$year, altcrime$neighborhood)
altcrime<-read.csv("altcrimev1.csv")
head(altcrime)
plot(altcrime$year, altcrime$neighborhood)
altcrime<-read.csv("altcrimev1.csv")
head(altcrime)
plot(altcrime$year, altcrime$neighborhood)
altcrime<-read.csv("altcrimev1.csv")
altcrime<-read.csv("altcrimev1.csv")
head(altcrime)
plot(altcrime$year, altcrime$neighborhood)
unique(altcrime$year)
