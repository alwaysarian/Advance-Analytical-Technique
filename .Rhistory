training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
<<<<<<< HEAD
knn4 <- train(PopSex ~ ., data = training, method = "Linda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(knn4, list(.lambda = 3))
knn4_pred <- predict(knn4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
plot(density(Accuracies))
knn4
knn4 <- train(PopSex ~ ., data = training, method = "Linda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
# this time get ALL predictors
=======
pda4 <- train(PopSex ~ ., data = training, method = "pda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.lambda = 2))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(pda4_pred,testing$PopSex)$overall["Accuracy"]
}
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
>>>>>>> c366098756d68c37760d2af766458b056d04171a
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
<<<<<<< HEAD
library(MASS)
library(caret)
Accuracies <- c(0.00)
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
knn4 <- train(PopSex ~ ., data = training, method = "Linda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
qhp <- read.csv("qhp.csv")
qhp$metal_level <- as.factor(qhp$metal_level)
cleandataqhp <- qhp[c(4,24, 26:62)]
dim(cleandataqhp)
cqhp <- cbind(cleandataqhp["metal_level"], scale(cleandataqhp[2:39]))
require(MASS)
require(caret)
require(nnet)
Accuracies <- c(0.00)
for (i in seq(1))
{
inTrain <- createDataPartition(cqhp$metal_level, p = .80, list = FALSE)
cqhp.nn4 <- nnet(metal_level ~ ., data = cqhp, subset = inTrain, size = 4, rang = 0.5,
decay = 5e-4, maxit = 20)
Accuracies[i] <- tryCatch({
confusionMatrix(cqhp$metal_level[-inTrain], predict(cqhp.nn4, cqhp[-inTrain,], type = "class"))$overall["Accuracy"]
}, error = function(err) { Accuracies[i] <- NA })
}
summary(Accuracies)
acclen = length(na.omit(Accuracies))
plot(density(na.omit(Accuracies)), main = paste('Neural Network accuracies:',acclen, 'runs') )
qhp <- read.csv("qhp.csv")
qhp$metal_level <- as.factor(qhp$metal_level)
cleandataqhp <- qhp[c(4,24, 26:62)]
dim(cleandataqhp)
cqhp <- cbind(cleandataqhp["metal_level"], scale(cleandataqhp[2:39]))
require(MASS)
require(caret)
require(nnet)
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(cqhp$metal_level, p = .80, list = FALSE)
cqhp.nn4 <- nnet(metal_level ~ ., data = cqhp, subset = inTrain, size = 4, rang = 0.5,
decay = 5e-4, maxit = 200)
Accuracies[i] <- tryCatch({
confusionMatrix(cqhp$metal_level[-inTrain], predict(cqhp.nn4, cqhp[-inTrain,], type = "class"))$overall["Accuracy"]
}, error = function(err) { Accuracies[i] <- NA })
}
summary(Accuracies)
acclen = length(na.omit(Accuracies))
plot(density(na.omit(Accuracies)), main = paste('Neural Network accuracies:',acclen, 'runs') )
=======
setwd("C:/Users/Nucleus/Desktop/Project/Advance-Analytical-Technique")
altcrime<-read.csv(altcrime.csv)
altcrime<-read.csv("altcrime.csv")
head(altcrime)
plot(as.factor(altcrime$crime)), altcrime$beat)
head(altcrime)
plot(altcrime$crime, altcrime$beat)
plot(altcrime$crime, altcrime$neighborhood)
unique(altcrime$crime)
table
table(altcrime$crime)
plot(table(altcrime$crime))
#Load libraries,
require(ggplot2)
require(animation)
require(dplyr)
#Load data
edeaths <- read.csv('altcrime.csv')
#Load the map data, set color value to -1
s = map_data('world')
install.packages("maps")
#Load libraries,
require(ggplot2)
require(animation)
require(dplyr)
#Load data
edeaths <- read.csv('altcrime.csv')
#Load the map data, set color value to -1
s = map_data('world')
s
s$colour = -1
require(ggplot2)
require(animation)
require(dplyr)
install.packages("animation")
require(ggplot2)
require(animation)
require(dplyr)
#Load data
altcrime <- read.csv('altcrime.csv')
#Load the map data, set color value to -1
s = map_data('world')
s$colour = -1
head(altcrime)
#Load data
altcrime <- read.csv('altcrime.csv')
#Load the map data, set color value to -1
s = map_data('world')
s$colour = -1
#malaria estimated  deaths
#create a list of years for use in both plots
years <- altcrime$date
head(years)
saveGIF(
for (yr in years ){
print(yr)
altcrime<-read.csv("altcrimev1.csv")
head(altcrime)
plot(altcrime$year, altcrime$neighborhood)
altcrime<-read.csv("altcrimev1.csv")
head(altcrime)
plot(altcrime$year, altcrime$neighborhood)
altcrime<-read.csv("altcrimev1.csv")
head(altcrime)
plot(altcrime$year, altcrime$neighborhood)
altcrime<-read.csv("altcrimev1.csv")
altcrime<-read.csv("altcrimev1.csv")
head(altcrime)
plot(altcrime$year, altcrime$neighborhood)
unique(altcrime$year)
>>>>>>> c366098756d68c37760d2af766458b056d04171a
eddat <- read.csv('EdgarMDPraveen.csv', as.is = T);
attach(eddat)
table(eddat$group)
require(caret) #select tuning parameters
require(e1071) #SVM
eddat <- read.csv('EdgarMDPraveen.csv', as.is = T);
attach(eddat)
#six group
dm6 <- eddat[which(group == 'AfA' | group == 'AsA'| group == 'EA'| group == 'NA'| group == 'HW'),];
sapply(dm6, function(x) sum(!is.na(x))/length(x))
colSums(is.na(eddat))
table(na.omit(dm6[,c(9,12,13,16,17,19,20,22,23,24)])$group)#14,25
dm <- na.omit(dm6[,c(9,12,13,16,17,19,20,22,23,24)])
dm$group <- as.factor(dm$group)
dm <- cbind(dm["group"], scale(dm[,c(2:10)]) )
# time how long it takes
start_time <- Sys.time()
Accuracies <- c(0.00)
# suppress console output
sink('sinktest.txt')
for (i in seq(100))
{
# sample
inTrain <- createDataPartition(dm$group, p = .80, list = FALSE)
dm.navg <- avNNet(dm[c(2:10)], dm$group, subset = inTrain, size = 2, rang = 0.5, decay = 5e-4, maxit = 200, repeats = 50)
Accuracies[i] <- confusionMatrix(dm$group[-inTrain], predict(dm.navg, dm[-inTrain,], type = "class"))$overall["Accuracy"]
}
# turn output on again
sink()
summary(Accuracies)
acclen = length(na.omit(Accuracies))
plot(density(Accuracies), main = paste('Average Neural Network Model accuracies:',acclen, 'runs') )
confusionMatrix(dm$group[-inTrain], predict(dm.navg, dm[-inTrain,], type = "class"))
table(eddat$group)
require(caret) #select tuning parameters
require(e1071) #SVM
eddat <- read.csv('EdgarMDPraveen.csv', as.is = T);
attach(eddat)
#six group
dm6 <- eddat[which(group == 'AfA' | group == 'AsA'| group == 'EA'| group == 'NA'| group == 'HW'),];
sapply(dm6, function(x) sum(!is.na(x))/length(x))
colSums(is.na(eddat))
table(na.omit(dm6[,c(9,12,13,16,17,19,20,22,23,24,14,25)])$group)#
dm <- na.omit(dm6[,c(9,12,13,16,17,19,20,22,23,24, 14,25)])
dm$group <- as.factor(dm$group)
dm <- cbind(dm["group"], scale(dm[,c(2:10)]) )
table(dm$group)
require(caret) #select tuning parameters
require(e1071) #SVM
eddat <- read.csv('EdgarMDPraveen.csv', as.is = T);
attach(eddat)
#six group
dm6 <- eddat[which(group == 'AfA' | group == 'AsA'| group == 'EA'| group == 'NA'| group == 'HW'),];
sapply(dm6, function(x) sum(!is.na(x))/length(x))
colSums(is.na(eddat))
table(na.omit(dm6[,c(9,12,13,16,17,19,20,22,23,24,14,25)])$group)#
table(eddat$group)
eddat <- read.csv('EdgarMDPraveen1.csv', as.is = T);
attach(eddat)
head(eddat)
table(eddat$group)
eddat <- read.csv('EdgarMDPraveen1.csv', as.is = T);
attach(eddat)
table(eddat$group)
require(caret) #select tuning parameters
require(e1071) #SVM
eddat <- read.csv('EdgarMDPraveen1.csv', as.is = T);
attach(eddat)
#six group
dm6 <- eddat[which(group == 'AfA' | group == 'AsA'| group == 'EA'| group == 'NAm'| group == 'HW'),];
sapply(dm6, function(x) sum(!is.na(x))/length(x))
colSums(is.na(eddat))
table(na.omit(dm6[,c(9,12,13,16,17,19,20,22,23,24,14,25)])$group)#
dm <- na.omit(dm6[,c(9,12,13,16,17,19,20,22,23,24, 14,25)])
dm$group <- as.factor(dm$group)
dm <- cbind(dm["group"], scale(dm[,c(2:12)]) )
# time how long it takes
start_time <- Sys.time()
Accuracies <- c(0.00)
# suppress console output
sink('sinktest.txt')
for (i in seq(100))
{
# sample
inTrain <- createDataPartition(dm$group, p = .80, list = FALSE)
dm.navg <- avNNet(dm[c(2:12)], dm$group, subset = inTrain, size = 2, rang = 0.5, decay = 5e-4, maxit = 200, repeats = 50)
Accuracies[i] <- confusionMatrix(dm$group[-inTrain], predict(dm.navg, dm[-inTrain,], type = "class"))$overall["Accuracy"]
}
# turn output on again
sink()
summary(Accuracies)
acclen = length(na.omit(Accuracies))
plot(density(Accuracies), main = paste('Average Neural Network Model accuracies:',acclen, 'runs') )
require(caret) #select tuning parameters
require(e1071) #SVM
eddat <- read.csv('EdgarMDPraveen1.csv', as.is = T);
attach(eddat)
#six group
dm6 <- eddat[which(group == 'AfA' | group == 'AsA'| group == 'EA'| group == 'NAm'| group == 'HW'),];
sapply(dm6, function(x) sum(!is.na(x))/length(x))
colSums(is.na(eddat))
table(na.omit(dm6[,c(9,12,13,16,17,19,20,22,23,24)])$group)#,14,25
dm <- na.omit(dm6[,c(9,12,13,16,17,19,20,22,23,24)])
dm$group <- as.factor(dm$group)
dm <- cbind(dm["group"], scale(dm[,c(2:10)]) )
# time how long it takes
start_time <- Sys.time()
Accuracies <- c(0.00)
# suppress console output
sink('sinktest.txt')
for (i in seq(100))
{
# sample
inTrain <- createDataPartition(dm$group, p = .80, list = FALSE)
dm.navg <- avNNet(dm[c(2:10)], dm$group, subset = inTrain, size = 2, rang = 0.5, decay = 5e-4, maxit = 200, repeats = 50)
Accuracies[i] <- confusionMatrix(dm$group[-inTrain], predict(dm.navg, dm[-inTrain,], type = "class"))$overall["Accuracy"]
}
# turn output on again
sink()
summary(Accuracies)
acclen = length(na.omit(Accuracies))
plot(density(Accuracies), main = paste('Average Neural Network Model accuracies:',acclen, 'runs') )
require(caret) #select tuning parameters
require(e1071) #SVM
eddat <- read.csv('EdgarMDPraveen1.csv', as.is = T);
attach(eddat)
#six group
dm6 <- eddat[which(group == 'AfA' | group == 'AsA'| group == 'EA'| group == 'NAm'| group == 'HW'),];
sapply(dm6, function(x) sum(!is.na(x))/length(x))
colSums(is.na(eddat))
table(na.omit(dm6[,c(9,12,13,16,17,19,20,22,23,24,14,25)])$group)#
dm <- na.omit(dm6[,c(9,12,13,16,17,19,20,22,23,24,14,25)])
dm$group <- as.factor(dm$group)
require(caret) #select tuning parameters
require(e1071) #SVM
eddat <- read.csv('EdgarMDPraveen1.csv', as.is = T);
attach(eddat)
#six group
dm6 <- eddat[which(group == 'AfA' | group == 'AsA'| group == 'EA'| group == 'NAm'| group == 'HW'),];
colSums(is.na(eddat))
table(na.omit(dm6[,c(9,12,13,16,17,19,20,22,23,24,14,25)])$group)#
dm <- na.omit(dm6[,c(9,12,13,16,17,19,20,22,23,24,14,25)])
dm$group <- as.factor(dm$group)
dm <- cbind(dm["group"], scale(dm[,c(2:10)]) )
# time how long it takes
start_time <- Sys.time()
Accuracies <- c(0.00)
# suppress console output
sink('sinktest.txt')
for (i in seq(100))
{
# sample
inTrain <- createDataPartition(dm$group, p = .80, list = FALSE)
dm.navg <- avNNet(dm[c(2:10)], dm$group, subset = inTrain, size = 2, rang = 0.5, decay = 5e-4, maxit = 200, repeats = 50)
Accuracies[i] <- confusionMatrix(dm$group[-inTrain], predict(dm.navg, dm[-inTrain,], type = "class"))$overall["Accuracy"]
}
# turn output on again
sink()
summary(Accuracies)
acclen = length(na.omit(Accuracies))
plot(density(Accuracies), main = paste('Average Neural Network Model accuracies:',acclen, 'runs') )
require(caret) #select tuning parameters
require(e1071) #SVM
eddat <- read.csv('EdgarMDPraveen1.csv', as.is = T);
attach(eddat)
#six group
dm6 <- eddat[which(group == 'AfA' | group == 'AsA'| group == 'EA'| group == 'NAm'| group == 'HW'),];
colSums(is.na(eddat))
table(na.omit(dm6[,c(9,12,13,16,17,19,20,22,23,24,14,25)])$group)#
dm <- na.omit(dm6[,c(9,12,13,16,17,19,20,22,23,24,14,25)])
dm$group <- as.factor(dm$group)
dm <- cbind(dm["group"], scale(dm[,c(2:12)]) )
# time how long it takes
start_time <- Sys.time()
Accuracies <- c(0.00)
# suppress console output
sink('sinktest.txt')
for (i in seq(100))
{
# sample
inTrain <- createDataPartition(dm$group, p = .80, list = FALSE)
dm.navg <- avNNet(dm[c(2:12)], dm$group, subset = inTrain, size = 2, rang = 0.5, decay = 5e-4, maxit = 200, repeats = 20)
Accuracies[i] <- confusionMatrix(dm$group[-inTrain], predict(dm.navg, dm[-inTrain,], type = "class"))$overall["Accuracy"]
}
# turn output on again
sink()
summary(Accuracies)
acclen = length(na.omit(Accuracies))
plot(density(Accuracies), main = paste('Average Neural Network Model accuracies:',acclen, 'runs') )
eddat <- read.csv('EdgarMDPraveen1.csv', as.is = T);
attach(eddat)
#six group
dm6 <- eddat[which(group == 'AfA' | group == 'AsA'| group == 'EA'| group == 'NAm'| group == 'HW'),];
colSums(is.na(eddat))
table(na.omit(dm6[,c(9,12,13,16,17,19,20,22,23,24,14,25,11,15,18,21,29)])$group)#
require(caret) #select tuning parameters
require(e1071) #SVM
eddat <- read.csv('EdgarMDPraveen1.csv', as.is = T);
attach(eddat)
#six group
dm6 <- eddat[which(group == 'AfA' | group == 'AsA'| group == 'EA'| group == 'NAm'| group == 'HW'),];
colSums(is.na(eddat))
table(na.omit(dm6[,c(9,12,13,16,17,19,20,22,23,24,14,25,11,15,18,21,29)])$group)#
dm <- na.omit(dm6[,c(9,12,13,16,17,19,20,22,23,24,14,25,11,15,18,21,29)])
dm$group <- as.factor(dm$group)
dm <- cbind(dm["group"], scale(dm[,c(2:17)]) )
# time how long it takes
start_time <- Sys.time()
Accuracies <- c(0.00)
# suppress console output
sink('sinktest.txt')
for (i in seq(100))
{
# sample
inTrain <- createDataPartition(dm$group, p = .80, list = FALSE)
dm.navg <- avNNet(dm[c(2:17)], dm$group, subset = inTrain, size = 2, rang = 0.5, decay = 5e-4, maxit = 200, repeats = 20)
Accuracies[i] <- confusionMatrix(dm$group[-inTrain], predict(dm.navg, dm[-inTrain,], type = "class"))$overall["Accuracy"]
}
# turn output on again
sink()
summary(Accuracies)
acclen = length(na.omit(Accuracies))
plot(density(Accuracies), main = paste('Average Neural Network Model accuracies:',acclen, 'runs') )
require(caret) #select tuning parameters
require(e1071) #SVM
eddat <- read.csv('EdgarMDPraveen1.csv', as.is = T);
attach(eddat)
#six group
dm6 <- eddat[which(group == 'AfA' | group == 'AsA'| group == 'EA'| group == 'NAm'| group == 'HW'),];
colSums(is.na(eddat))
table(na.omit(dm6[,c(9,12,13,16,17,19,20,22,23,24,14,25,11,15,18,21,29)])$group)#
dm <- na.omit(dm6[,c(9,12,13,16,17,19,20,22,23,24,14,25,11,15,18,21,29)])
dm$group <- as.factor(dm$group)
dm <- cbind(dm["group"], scale(dm[,c(2:17)]) )
# time how long it takes
start_time <- Sys.time()
Accuracies <- c(0.00)
# suppress console output
sink('sinktest.txt')
for (i in seq(100))
{
# sample
inTrain <- createDataPartition(dm$group, p = .80, list = FALSE)
dm.navg <- avNNet(dm[c(2:17)], dm$group, subset = inTrain, size = 2, rang = 0.5, decay = 5e-4, maxit = 200, repeats = 20)
Accuracies[i] <- confusionMatrix(dm$group[-inTrain], predict(dm.navg, dm[-inTrain,], type = "class"))$overall["Accuracy"]
}
# turn output on again
sink()
summary(Accuracies)
acclen = length(na.omit(Accuracies))
plot(density(Accuracies), main = paste('Average Neural Network Model accuracies:',acclen, 'runs') )
# time how long it takes
start_time <- Sys.time()
Accuracies <- c(0.00)
# suppress console output
sink('sinktest.txt')
for (i in seq(100))
{
# sample
inTrain <- createDataPartition(dm$group, p = .80, list = FALSE)
dm.navg <- avNNet(dm[c(2:17)], dm$group, subset = inTrain, size = 2, rang = 0.5, decay = 5e-4, maxit = 200, repeats = 20)
Accuracies[i] <- confusionMatrix(dm$group[-inTrain], predict(dm.navg, dm[-inTrain,], type = "class"))$overall["Accuracy"]
}
# turn output on again
sink()
summary(Accuracies)
acclen = length(na.omit(Accuracies))
plot(density(Accuracies), main = paste('Average Neural Network Model accuracies:',acclen, 'runs') )
require(caret) #select tuning parameters
require(e1071) #SVM
eddat <- read.csv('EdgarMDPraveen1.csv', as.is = T);
attach(eddat)
#six group
dm6 <- eddat[which(group == 'AfA' | group == 'AsA'| group == 'EA'| group == 'NAm'| group == 'HW'),];
colSums(is.na(eddat))
table(na.omit(dm6[,c(9,12,13,16,17,19,20,22,23,24,14,25,11,15,18,21,29)])$group)#
dm <- na.omit(dm6[,c(9,12,13,16,17,19,20,22,23,24,14,25,11,15,18,21,29)])
dm$group <- as.factor(dm$group)
dm <- cbind(dm["group"], scale(dm[,c(2:17)]) )
# time how long it takes
start_time <- Sys.time()
Accuracies <- c(0.00)
# suppress console output
sink('sinktest.txt')
for (i in seq(100))
{
# sample
inTrain <- createDataPartition(dm$group, p = .80, list = FALSE)
dm.navg <- avNNet(dm[c(2:16)], dm$group, subset = inTrain, size = 2, rang = 0.5, decay = 5e-4, maxit = 200, repeats = 20)
Accuracies[i] <- confusionMatrix(dm$group[-inTrain], predict(dm.navg, dm[-inTrain,], type = "class"))$overall["Accuracy"]
}
# turn output on again
sink()
summary(Accuracies)
acclen = length(na.omit(Accuracies))
plot(density(Accuracies), main = paste('Average Neural Network Model accuracies:',acclen, 'runs') )
require(caret) #select tuning parameters
require(e1071) #SVM
eddat <- read.csv('EdgarMDPraveen1.csv', as.is = T);
attach(eddat)
#six group
dm6 <- eddat[which(group == 'AfA' | group == 'AsA'| group == 'EA'| group == 'NAm'| group == 'HW'),];
colSums(is.na(eddat))
table(na.omit(dm6[,c(9,12,13,16,17,19,20,22,23,24,14,25,11,15,18,21,29)])$group)#
dm <- na.omit(dm6[,c(9,12,13,16,17,19,20,22,23,24,14,25,11,15,18,21,29)])
dm$group <- as.factor(dm$group)
dm <- cbind(dm["group"], scale(dm[,c(2:17)]) )
# time how long it takes
start_time <- Sys.time()
Accuracies <- c(0.00)
# suppress console output
sink('sinktest.txt')
for (i in seq(100))
{
# sample
inTrain <- createDataPartition(dm$group, p = .80, list = FALSE)
dm.navg <- avNNet(dm[c(2:17)], dm$group, subset = inTrain, size = 2, rang = 0.5, decay = 5e-4, maxit = 200, repeats = 20)
Accuracies[i] <- confusionMatrix(dm$group[-inTrain], predict(dm.navg, dm[-inTrain,], type = "class"))$overall["Accuracy"]
}
# turn output on again
sink()
summary(Accuracies)
acclen = length(na.omit(Accuracies))
plot(density(Accuracies), main = paste('Average Neural Network Model accuracies:',acclen, 'runs') )
table(dm$group)
require(caret) #select tuning parameters
require(e1071) #SVM
eddat <- read.csv('EdgarMDPraveen1.csv', as.is = T);
attach(eddat)
#six group
dm6 <- eddat[which(group == 'AfA' | group == 'AsA'| group == 'EA'| group == 'NAm'| group == 'HW'),];
colSums(is.na(eddat))
table(na.omit(dm6[,c(9,12,13,16,17,19,20,22,23,24,14,25)])$group)#,11,15,18,21,29
dm <- na.omit(dm6[,c(9,12,13,16,17,19,20,22,23,24,14,25)])
dm$group <- as.factor(dm$group)
dm <- cbind(dm["group"], scale(dm[,c(2:12)]) )
# time how long it takes
start_time <- Sys.time()
Accuracies <- c(0.00)
# suppress console output
sink('sinktest.txt')
for (i in seq(100))
{
# sample
inTrain <- createDataPartition(dm$group, p = .80, list = FALSE)
dm.navg <- avNNet(dm[c(2:12)], dm$group, subset = inTrain, size = 2, rang = 0.5, decay = 5e-4, maxit = 200, repeats = 20)
Accuracies[i] <- confusionMatrix(dm$group[-inTrain], predict(dm.navg, dm[-inTrain,], type = "class"))$overall["Accuracy"]
}
eddat <- read.csv('EdgarMDPraveen1.csv', as.is = T);
attach(eddat)
#six group
dm6 <- eddat[which(group == 'AfA' | group == 'AsA'| group == 'EA'| group == 'NAm'| group == 'HW'),];
colSums(is.na(eddat))
table(na.omit(dm6[,c(9,12,13,16,17,19,20,22,23,24,14,25,15,18,21,29)])$group)#,11,15,18,21,29
