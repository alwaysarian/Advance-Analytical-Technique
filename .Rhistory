library(caret)
Accuracies <- c(0.00)
for (i in seq(20))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
knn4 <- train(PopSex ~ ., data = training, method = "knn",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(knn4, list(.k = 3))
knn4_pred <- predict(knn4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
knn4
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(20))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
knn4 <- train(PopSex ~ ., data = training, method = "knn",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(knn4, list(.lambda = 3))
knn4_pred <- predict(knn4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(20))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
knn4 <- train(PopSex ~ ., data = training, method = "knn",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(knn4, list(.k = 3))
knn4_pred <- predict(knn4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]
}
Accuracies <- c(0.00)
for (i in seq(20))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
knn4 <- train(PopSex ~ ., data = training, method = "pda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(knn4, list(.lambda = 3))
knn4_pred <- predict(knn4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(10))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
knn4 <- train(PopSex ~ ., data = training, method = "logreg",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(knn4, list(.lambda = 3))
knn4_pred <- predict(knn4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
knn4
Accuracies <- c(0.00)
for (i in seq(10))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
knn4 <- train(PopSex ~ ., data = training, method = "logreg",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(knn4, list(.lambda = 3))
knn4_pred <- predict(knn4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
knn4
Accuracies <- c(0.00)
for (i in seq(10))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
knn4 <- train(PopSex ~ ., data = training, method = "logreg",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(knn4, list(.lambda = 3))
knn4_pred <- predict(knn4,newdata = testing)
#Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]
}
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
knn4 <- train(PopSex ~ ., data = training, method = "logreg",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(10))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
knn4 <- train(PopSex ~ ., data = training, method = "pda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(knn4, list(.lambda = 3))
knn4_pred <- predict(knn4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]
}
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
# this time get ALL predictors
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
# many columns are Nas
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(10))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
knn4 <- train(PopSex ~ ., data = training, method = "pda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(knn4, list(.lambda = 3))
knn4_pred <- predict(knn4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
# this time get ALL predictors
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(500))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
knn4 <- train(PopSex ~ ., data = training, method = "pda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(knn4, list(.lambda = 3))
knn4_pred <- predict(knn4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
plot(density(Accuracies))
knn4
confusionMatrix(knn4_pred,testing$PopSex)
confusionMatrix(knn4)
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
# this time get ALL predictors
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(5))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
knn4 <- train(PopSex ~ ., data = training, method = "pda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(knn4, list(.lambda = 3))
knn4_pred <- predict(knn4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
# this time get ALL predictors
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
require(rpart)
# caret function
inTest <- createDataPartition(H4A$PopSex, p = .20, list = FALSE)
# subset = holdout record numbers, NOT using train function from caret
chdr <- rpart(PopSex ~ .,
data=H4A,
method = "class", subset = inTest,
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
control = rpart.control(usesurrogate = 0, maxsurrogate = 0))
library("caret")
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
# this time get ALL predictors
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
require(rpart)
# caret function
inTest <- createDataPartition(H4A$PopSex, p = .20, list = FALSE)
# subset = holdout record numbers, NOT using train function from caret
chdr <- rpart(PopSex ~ .,
data=H4A,
method = "class", subset = inTest,
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
control = rpart.control(usesurrogate = 0, maxsurrogate = 0))
confusionMatrix(H4A[inTest,"Popsex"],predict(chdr,newdata = H4A[inTest,], type = "class") )
confusionMatrix(SSU[inTest,"chd"],predict(chdr,newdata = SSU[inTest,], type = "class") )
confusionMatrix(H4A[inTest,"Popsex"],predict(chdr,newdata = H4A[inTest,], type = "class") )
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
# this time get ALL predictors
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
require(rpart)
# caret function
inTest <- createDataPartition(H4A$PopSex, p = .20, list = FALSE)
# subset = holdout record numbers, NOT using train function from caret
chdr <- rpart(PopSex ~ .,
data=H4A,
method = "class", subset = inTest,
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
control = rpart.control(usesurrogate = 0, maxsurrogate = 0))
confusionMatrix(H4A[inTest,"Popsex"],predict(chdr,newdata = H4A[inTest,], type = "class") )
chdr
library(MASS) # contains the data
library(caret) #select tuning parameters
#library(e1071) #SVM
set.seed(7); #replicable across our PCs? no.
# South African heart disease data
sahdd <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/sahdd.csv', as.is = T);
# sahdd$chd <- as.factor(sahdd$chd)
# exclude row number (first column)
# scale all continuous predictors, leave out famhist
SS <- cbind(sahdd["chd"], scale(sahdd[,c(-1,-6,-11)]) )
# SSU includes family history
SSU <- sahdd[,c(2:11)]
SS[,"chd"] <- as.factor(SS[,"chd"])
SSU[,"chd"] <- as.factor(SSU[,"chd"])
SSU[,"famhist"] <- as.factor(SSU[,"famhist"])
# or SS$chd <- as.factor(SS$chd)
chdr <- rpart(chd ~ .,
data=SSU,
method = "class", subset = inTest,
parms = list(split = "gini"),
control = rpart.control(usesurrogate = 0, maxsurrogate = 0))
confusionMatrix(SSU[inTest,"chd"],predict(chdr,newdata = SSU[inTest,], type = "class") )
chdir
chdr
Sens <- c(0.00)
for (i in seq(10)) # takes a while
{
inTrain <- createDataPartition(SSU$chd, p = .75, list = FALSE) # compact now
training <- SSU[inTrain,]
test <- SSU[-inTrain,]
HHP <- train(chd~., data = training,
method = "rpart",
control = rpart.control(minsplit = 20, cp = 0.01)) # bootstrap
#trControl = trainControl(method = "cv"))
cm <- confusionMatrix(SSU[-inTrain,"chd"], predict(HHP, newdata = SSU[-inTrain,]))
Sens[i] <- cm$table[1,1] / (cm$table[1,1] + cm$table[2,1])
}
summary(Sens) # not great
qhp <- read.csv("qhp.csv")
qhp$issuer_name <- as.factor(qhp$issuer_name)
cleandataqhp <- qhp[c(5,24,26:62)]
dim(cleandataqhp)
cqhp <- cbind(cleandataqhp["issuer_name"], scale(cleandataqhp[2:39]))
require(MASS)
require(caret)
require(nnet)
Accuracies <- c(0.00)
for (i in seq(2))
{
inTrain <- createDataPartition(cqhp$issuer_name, p = .75, list = FALSE)
cqhp.nn4 <- nnet(issuer_name ~ ., data = cqhp, subset = inTrain, size = 4, rang = 0.5,
decay = 5e-4, maxit = 20)
Accuracies[i] <- tryCatch({
confusionMatrix(cqhp$issuer_name[-inTrain], predict(cqhp.nn4, cqhp[-inTrain,], type = "class"))$overall["Accuracy"]
}, error = function(err) { Accuracies[i] <- NA })
}
summary(Accuracies)
acclen = length(na.omit(Accuracies))
plot(density(na.omit(Accuracies)), main = paste('Neural Network accuracies:',acclen, 'runs') )
setwd("C:/Users/pnkum/Desktop/Project/Advance-Analytical-Technique")
qhp <- read.csv("qhp.csv")
qhp$metal_level <- as.factor(qhp$metal_level)
cleandataqhp <- qhp[c(4,24, 26:62)]
dim(cleandataqhp)
cqhp <- cbind(cleandataqhp["metal_level"], scale(cleandataqhp[2:39]))
require(MASS)
require(caret)
require(nnet)
Accuracies <- c(0.00)
for (i in seq(1))
{
inTrain <- createDataPartition(cqhp$metal_level, p = .80, list = FALSE)
cqhp.nn4 <- nnet(metal_level ~ ., data = cqhp, subset = inTrain, size = 4, rang = 0.5,
decay = 5e-4, maxit = 200)
Accuracies[i] <- tryCatch({
confusionMatrix(cqhp$metal_level[-inTrain], predict(cqhp.nn4, cqhp[-inTrain,], type = "class"))$overall["Accuracy"]
}, error = function(err) { Accuracies[i] <- NA })
}
qhp$issuer_name <- as.factor(qhp$issuer_name)
cleandataqhp <- qhp[c(5,24,26:62)]
dim(cleandataqhp)
cqhp <- cbind(cleandataqhp["issuer_name"], scale(cleandataqhp[2:39]))
require(MASS)
require(caret)
require(nnet)
Accuracies <- c(0.00)
for (i in seq(2))
{
inTrain <- createDataPartition(cqhp$issuer_name, p = .75, list = FALSE)
cqhp.nn4 <- nnet(issuer_name ~ ., data = cqhp, subset = inTrain, size = 4, rang = 0.5,
decay = 5e-4, maxit = 20)
Accuracies[i] <- tryCatch({
confusionMatrix(cqhp$issuer_name[-inTrain], predict(cqhp.nn4, cqhp[-inTrain,], type = "class"))$overall["Accuracy"]
}, error = function(err) { Accuracies[i] <- NA })
}
summary(Accuracies)
acclen = length(na.omit(Accuracies))
plot(density(na.omit(Accuracies)), main = paste('Neural Network accuracies:',acclen, 'runs') )
qhp$issuer_name <- as.factor(qhp$issuer_name)
cleandataqhp <- qhp[c(5,24,26:62)]
dim(cleandataqhp)
cqhp <- cbind(cleandataqhp["issuer_name"], scale(cleandataqhp[2:39]))
inTrain <- createDataPartition(cqhp$issuer_name, p = .75, list = FALSE)
cqhp.nn4 <- nnet(issuer_name ~ ., data = cqhp, subset = inTrain, size = 4, rang = 0.5,
decay = 5e-4, maxit = 20)
confusionMatrix(cqhp$issuer_name[-inTrain], predict(cqhp.nn4, cqhp[-inTrain,], type = "class"))
confusionMatrix(table(cqhp$issuer_name[-inTrain]), table(predict(cqhp.nn4, cqhp[-inTrain,])
)
)
table(cqhp$issuer_name[-inTrain])
table(predict(cqhp.nn4, cqhp[-inTrain,])
)
confusionMatrix(table(cqhp$issuer_name[-inTrain]), table(predict(cqhp.nn4, cqhp[-inTrain,])), type = "class")
table(cqhp$issuer_name[-inTrain])
predict(cqhp.nn4, cqhp[-inTrain,])
predict(cqhp.nn4, cqhp[-inTrain,])
confusionMatrix(cqhp$issuer_name[-inTrain], predict(cqhp.nn4, cqhp[-inTrain,]))
confusionMatrix(cqhp$issuer_name[-inTrain], predict(cqhp.nn4, new data = cqhp[-inTrain,]))
confusionMatrix(cqhp$issuer_name[-inTrain], predict(cqhp.nn4, newdata = cqhp[-inTrain,]))
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
# this time get ALL predictors
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(5))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
knn4 <- train(PopSex ~ ., data = training, method = "Linda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(knn4, list(.lambda = 3))
knn4_pred <- predict(knn4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
plot(density(Accuracies))
knn4
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
# this time get ALL predictors
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(5))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
knn4 <- train(PopSex ~ ., data = training, method = "Linda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(knn4, list(.lambda = 3))
knn4_pred <- predict(knn4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
plot(density(Accuracies))
knn4
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
# this time get ALL predictors
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(5))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
knn4 <- train(PopSex ~ ., data = training, method = "Linda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(knn4, list(.lambda = 3))
knn4_pred <- predict(knn4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
plot(density(Accuracies))
knn4
knn4 <- train(PopSex ~ ., data = training, method = "Linda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
# this time get ALL predictors
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
library(MASS)
library(caret)
Accuracies <- c(0.00)
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
knn4 <- train(PopSex ~ ., data = training, method = "Linda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
qhp <- read.csv("qhp.csv")
qhp$metal_level <- as.factor(qhp$metal_level)
cleandataqhp <- qhp[c(4,24, 26:62)]
dim(cleandataqhp)
cqhp <- cbind(cleandataqhp["metal_level"], scale(cleandataqhp[2:39]))
require(MASS)
require(caret)
require(nnet)
Accuracies <- c(0.00)
for (i in seq(1))
{
inTrain <- createDataPartition(cqhp$metal_level, p = .80, list = FALSE)
cqhp.nn4 <- nnet(metal_level ~ ., data = cqhp, subset = inTrain, size = 4, rang = 0.5,
decay = 5e-4, maxit = 20)
Accuracies[i] <- tryCatch({
confusionMatrix(cqhp$metal_level[-inTrain], predict(cqhp.nn4, cqhp[-inTrain,], type = "class"))$overall["Accuracy"]
}, error = function(err) { Accuracies[i] <- NA })
}
summary(Accuracies)
acclen = length(na.omit(Accuracies))
plot(density(na.omit(Accuracies)), main = paste('Neural Network accuracies:',acclen, 'runs') )
qhp <- read.csv("qhp.csv")
qhp$metal_level <- as.factor(qhp$metal_level)
cleandataqhp <- qhp[c(4,24, 26:62)]
dim(cleandataqhp)
cqhp <- cbind(cleandataqhp["metal_level"], scale(cleandataqhp[2:39]))
require(MASS)
require(caret)
require(nnet)
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(cqhp$metal_level, p = .80, list = FALSE)
cqhp.nn4 <- nnet(metal_level ~ ., data = cqhp, subset = inTrain, size = 4, rang = 0.5,
decay = 5e-4, maxit = 200)
Accuracies[i] <- tryCatch({
confusionMatrix(cqhp$metal_level[-inTrain], predict(cqhp.nn4, cqhp[-inTrain,], type = "class"))$overall["Accuracy"]
}, error = function(err) { Accuracies[i] <- NA })
}
summary(Accuracies)
acclen = length(na.omit(Accuracies))
plot(density(na.omit(Accuracies)), main = paste('Neural Network accuracies:',acclen, 'runs') )
