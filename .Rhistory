<<<<<<< HEAD
library(caret)
Accuracies <- c(0.00)
for (i in seq(20))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
knn4 <- train(PopSex ~ ., data = training, method = "knn",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(knn4, list(.k = 3))
knn4_pred <- predict(knn4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
knn4
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(20))
=======
list = FALSE)
training <-H4A[inTrain,]
# no longer needed !
#testing <-H4A[-inTrain,]
#testrecs<-as.numeric(rownames(testing)) # row(testing)[,1]
H4A.R <-lda(as.matrix(H4A[,c(2:72)]), H4A[,"PopSex"], data = HA4, prior = c(0.25,0.25,0.25,0.25), subset = -inTrain, CV = T)
Accuracies[i] <-confusionMatrix(H4A[-inTrain,"PopSex"], H4A.R$class)$overall["Accuracy"]
}
summary(Accuracies)
#  Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
# 0.07937 0.20635 0.25397 0.25021 0.28571 0.44444
plot(density(Accuracies))
library(class) #k-nearest neighbors
library(kknn) #weighted k-nearest neighbors
library(e1071) #SVM
library(caret) #select tuning parameters
library(MASS) # contains the data
library(reshape2) #assist in creating boxplots
library(ggplot2) #create boxplots
library(kernlab) #assist with SVM feature selection
library(pROC)
install.packages("kknn")
library(class) #k-nearest neighbors
library(kknn) #weighted k-nearest neighbors
library(e1071) #SVM
library(caret) #select tuning parameters
library(MASS) # contains the data
library(reshape2) #assist in creating boxplots
library(ggplot2) #create boxplots
library(kernlab) #assist with SVM feature selection
library(pROC)
install.packages("pROC")
library(class) #k-nearest neighbors
library(kknn) #weighted k-nearest neighbors
library(e1071) #SVM
library(caret) #select tuning parameters
library(MASS) # contains the data
library(reshape2) #assist in creating boxplots
library(ggplot2) #create boxplots
library(kernlab) #assist with SVM feature selection
library(pROC)
set.seed(7); #replicable across our PCs?
sahdd <-
read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/sahdd.csv',
as.is = T);
sahdd$chd <- as.factor(sahdd$chd)
SS <- cbind(sahdd[,c(1,11)], scale(sahdd[,c(-1,-6,-11)]) )
str(SS)
inTrain <- createDataPartition(y = SS$chd, # y = grouping variable,
stratified random split
p = .70, ## The proportion of records in the training set
list = FALSE)
train <- SS[inTrain,]
test <- SS[-inTrain,]
# ERRORS - book code, demo code from e1071 will not run
#linear.tune = tune.svm(chd~., data=train, kernel="linear",
cost=c(0.001, 0.01, 0.1, 1,5,10))
#poly.tune = tune.svm(chd~., data=train, kern
inTrain <- createDataPartition(y = SS$chd, # y = grouping variable,
stratified random split
p = .70, ## The proportion of records in the training set
list = FALSE)
inTrain <- createDataPartition(y = SS$chd, stratified random split p = .70, list = FALSE)
inTrain <- createDataPartition(y = SS$chd, stratified random = split p = .70, list = FALSE)
inTrain <- createDataPartition(y = SS$chd,  p = .70, list = FALSE)
train <- SS[inTrain,]
test <- SS[-inTrain,]
cost=c(0.001, 0.01, 0.1, 1,5,10))
cost=c(0.001, 0.01, 0.1, 1,5,10)
SS.ksvm <- ksvm(chd ~ .,
data=train,
kernel="rbfdot",
prob.model=TRUE )
SS.ksvm
cost=c(0.001, 0.01, 0.1, 1,5,10)
confusionMatrix(test$chd, predict(SS.ksvm, test) )
install.packages("rattle")
library("rattle")
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(5))
>>>>>>> c366098756d68c37760d2af766458b056d04171a
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
<<<<<<< HEAD
knn4 <- train(PopSex ~ ., data = training, method = "knn",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(knn4, list(.lambda = 3))
knn4_pred <- predict(knn4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(20))
=======
pda4 <- train(PopSex ~ ., data = training, method = "QdaCov",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.k = 3))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
warining()
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(5))
>>>>>>> c366098756d68c37760d2af766458b056d04171a
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
<<<<<<< HEAD
knn4 <- train(PopSex ~ ., data = training, method = "knn",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(knn4, list(.k = 3))
knn4_pred <- predict(knn4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]
}
Accuracies <- c(0.00)
for (i in seq(20))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
knn4 <- train(PopSex ~ ., data = training, method = "pda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(knn4, list(.lambda = 3))
knn4_pred <- predict(knn4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(10))
=======
pda4 <- train(PopSex ~ ., data = training, method = "QdaCov",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.k = 3))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
Hef <-  read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/HefM.csv', as.is = T);
str(Hef)
HefNB <- na.omit(Hef)
Accuracies <- c(0.00)
for (i in seq(20)) # only 20 because it takes a while
{
inTrain <- createDataPartition(y = HefNB$Pop, # y = grouping variable,
stratified random split
p = .70, ## The proportion of records in the training set
list = FALSE)
train <- HefNB[inTrain,]
test <- HefNB[-inTrain,]
nb2 <- train(Pop ~ ANS+INA+IOB+NAW+NBS+NO+PBD+ZS, data = train, method
= "nb",
trControl = ctrl,
tuneGrid = data.frame(usekernel = TRUE, fL = 0.5, adjust
= 5))
bps2 <- predict(nb2, newdata = test)
Accuracies[i] <- confusionMatrix(test$Pop,bps2)$overall["Accuracy"]
}
summary(Accuracies)
Accuracies <- c(0.00)
for (i in seq(20)) # only 20 because it takes a while
{
inTrain <- createDataPartition(y = HefNB$Pop, # y = grouping variable,
stratified random split
p = .70, ## The proportion of records in the training set
list = FALSE)
train <- HefNB[inTrain,]
test <- HefNB[-inTrain,]
nb2 <- train(Pop ~ ANS+INA+IOB+NAW+NBS+NO+PBD+ZS, data = train, method = "nb",
trControl = ctrl,
tuneGrid = data.frame(usekernel = TRUE, fL = 0.5, adjust
= 5))
bps2 <- predict(nb2, newdata = test)
Accura
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(5))
>>>>>>> c366098756d68c37760d2af766458b056d04171a
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
<<<<<<< HEAD
knn4 <- train(PopSex ~ ., data = training, method = "logreg",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(knn4, list(.lambda = 3))
knn4_pred <- predict(knn4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
knn4
Accuracies <- c(0.00)
for (i in seq(10))
=======
pda4 <- train(PopSex ~ ., data = training, method = "multinom",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.k = 3))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
pda4
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(5))
>>>>>>> c366098756d68c37760d2af766458b056d04171a
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
<<<<<<< HEAD
knn4 <- train(PopSex ~ ., data = training, method = "logreg",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(knn4, list(.lambda = 3))
knn4_pred <- predict(knn4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
knn4
Accuracies <- c(0.00)
for (i in seq(10))
=======
pda4 <- train(PopSex ~ ., data = training, method = "multinom",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.decay = 3))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]}
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(2))
>>>>>>> c366098756d68c37760d2af766458b056d04171a
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
<<<<<<< HEAD
knn4 <- train(PopSex ~ ., data = training, method = "logreg",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(knn4, list(.lambda = 3))
knn4_pred <- predict(knn4,newdata = testing)
#Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]
}
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
knn4 <- train(PopSex ~ ., data = training, method = "logreg",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(10))
=======
pda4 <- train(PopSex ~ ., data = training, method = "multinom",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.decay = 3))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(2))
>>>>>>> c366098756d68c37760d2af766458b056d04171a
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
<<<<<<< HEAD
knn4 <- train(PopSex ~ ., data = training, method = "pda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(knn4, list(.lambda = 3))
knn4_pred <- predict(knn4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]
}
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
# this time get ALL predictors
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
# many columns are Nas
=======
pda4 <- train(PopSex ~ ., data = training, method = "pda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.lamda = 3))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]}
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
>>>>>>> c366098756d68c37760d2af766458b056d04171a
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
library(MASS)
library(caret)
Accuracies <- c(0.00)
<<<<<<< HEAD
for (i in seq(10))
=======
for (i in seq(2))
>>>>>>> c366098756d68c37760d2af766458b056d04171a
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
<<<<<<< HEAD
knn4 <- train(PopSex ~ ., data = training, method = "pda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(knn4, list(.lambda = 3))
knn4_pred <- predict(knn4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
# this time get ALL predictors
=======
pda4 <- train(PopSex ~ ., data = training, method = "pda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.lambda = 3))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
>>>>>>> c366098756d68c37760d2af766458b056d04171a
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
library(MASS)
library(caret)
Accuracies <- c(0.00)
<<<<<<< HEAD
for (i in seq(500))
=======
for (i in seq(2))
>>>>>>> c366098756d68c37760d2af766458b056d04171a
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
<<<<<<< HEAD
knn4 <- train(PopSex ~ ., data = training, method = "pda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(knn4, list(.lambda = 3))
knn4_pred <- predict(knn4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
plot(density(Accuracies))
knn4
confusionMatrix(knn4_pred,testing$PopSex)
confusionMatrix(knn4)
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
# this time get ALL predictors
=======
pda4 <- train(PopSex ~ ., data = training, method = "pda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.lambda = 0))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
>>>>>>> c366098756d68c37760d2af766458b056d04171a
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
library(MASS)
library(caret)
Accuracies <- c(0.00)
<<<<<<< HEAD
for (i in seq(5))
=======
for (i in seq(2))
>>>>>>> c366098756d68c37760d2af766458b056d04171a
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
<<<<<<< HEAD
knn4 <- train(PopSex ~ ., data = training, method = "pda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(knn4, list(.lambda = 3))
knn4_pred <- predict(knn4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
# this time get ALL predictors
=======
pda4 <- train(PopSex ~ ., data = training, method = "pda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.lambda = 1))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
>>>>>>> c366098756d68c37760d2af766458b056d04171a
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
<<<<<<< HEAD
require(rpart)
# caret function
inTest <- createDataPartition(H4A$PopSex, p = .20, list = FALSE)
# subset = holdout record numbers, NOT using train function from caret
chdr <- rpart(PopSex ~ .,
data=H4A,
method = "class", subset = inTest,
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
control = rpart.control(usesurrogate = 0, maxsurrogate = 0))
library("caret")
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
# this time get ALL predictors
=======
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(2))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
pda4 <- train(PopSex ~ ., data = training, method = "pda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.lambda = 2))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
>>>>>>> c366098756d68c37760d2af766458b056d04171a
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
<<<<<<< HEAD
require(rpart)
# caret function
inTest <- createDataPartition(H4A$PopSex, p = .20, list = FALSE)
# subset = holdout record numbers, NOT using train function from caret
chdr <- rpart(PopSex ~ .,
data=H4A,
method = "class", subset = inTest,
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
control = rpart.control(usesurrogate = 0, maxsurrogate = 0))
confusionMatrix(H4A[inTest,"Popsex"],predict(chdr,newdata = H4A[inTest,], type = "class") )
confusionMatrix(SSU[inTest,"chd"],predict(chdr,newdata = SSU[inTest,], type = "class") )
confusionMatrix(H4A[inTest,"Popsex"],predict(chdr,newdata = H4A[inTest,], type = "class") )
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
# this time get ALL predictors
=======
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
>>>>>>> c366098756d68c37760d2af766458b056d04171a
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
<<<<<<< HEAD
require(rpart)
# caret function
inTest <- createDataPartition(H4A$PopSex, p = .20, list = FALSE)
# subset = holdout record numbers, NOT using train function from caret
chdr <- rpart(PopSex ~ .,
data=H4A,
method = "class", subset = inTest,
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
control = rpart.control(usesurrogate = 0, maxsurrogate = 0))
confusionMatrix(H4A[inTest,"Popsex"],predict(chdr,newdata = H4A[inTest,], type = "class") )
chdr
library(MASS) # contains the data
library(caret) #select tuning parameters
#library(e1071) #SVM
set.seed(7); #replicable across our PCs? no.
# South African heart disease data
sahdd <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/sahdd.csv', as.is = T);
# sahdd$chd <- as.factor(sahdd$chd)
# exclude row number (first column)
# scale all continuous predictors, leave out famhist
SS <- cbind(sahdd["chd"], scale(sahdd[,c(-1,-6,-11)]) )
# SSU includes family history
SSU <- sahdd[,c(2:11)]
SS[,"chd"] <- as.factor(SS[,"chd"])
SSU[,"chd"] <- as.factor(SSU[,"chd"])
SSU[,"famhist"] <- as.factor(SSU[,"famhist"])
# or SS$chd <- as.factor(SS$chd)
chdr <- rpart(chd ~ .,
data=SSU,
method = "class", subset = inTest,
parms = list(split = "gini"),
control = rpart.control(usesurrogate = 0, maxsurrogate = 0))
confusionMatrix(SSU[inTest,"chd"],predict(chdr,newdata = SSU[inTest,], type = "class") )
chdir
chdr
Sens <- c(0.00)
for (i in seq(10)) # takes a while
{
inTrain <- createDataPartition(SSU$chd, p = .75, list = FALSE) # compact now
training <- SSU[inTrain,]
test <- SSU[-inTrain,]
HHP <- train(chd~., data = training,
method = "rpart",
control = rpart.control(minsplit = 20, cp = 0.01)) # bootstrap
#trControl = trainControl(method = "cv"))
cm <- confusionMatrix(SSU[-inTrain,"chd"], predict(HHP, newdata = SSU[-inTrain,]))
Sens[i] <- cm$table[1,1] / (cm$table[1,1] + cm$table[2,1])
}
summary(Sens) # not great
qhp <- read.csv("qhp.csv")
qhp$issuer_name <- as.factor(qhp$issuer_name)
cleandataqhp <- qhp[c(5,24,26:62)]
dim(cleandataqhp)
cqhp <- cbind(cleandataqhp["issuer_name"], scale(cleandataqhp[2:39]))
require(MASS)
require(caret)
require(nnet)
Accuracies <- c(0.00)
for (i in seq(2))
{
inTrain <- createDataPartition(cqhp$issuer_name, p = .75, list = FALSE)
cqhp.nn4 <- nnet(issuer_name ~ ., data = cqhp, subset = inTrain, size = 4, rang = 0.5,
decay = 5e-4, maxit = 20)
Accuracies[i] <- tryCatch({
confusionMatrix(cqhp$issuer_name[-inTrain], predict(cqhp.nn4, cqhp[-inTrain,], type = "class"))$overall["Accuracy"]
}, error = function(err) { Accuracies[i] <- NA })
}
summary(Accuracies)
acclen = length(na.omit(Accuracies))
plot(density(na.omit(Accuracies)), main = paste('Neural Network accuracies:',acclen, 'runs') )
setwd("C:/Users/pnkum/Desktop/Project/Advance-Analytical-Technique")
qhp <- read.csv("qhp.csv")
qhp$metal_level <- as.factor(qhp$metal_level)
cleandataqhp <- qhp[c(4,24, 26:62)]
dim(cleandataqhp)
cqhp <- cbind(cleandataqhp["metal_level"], scale(cleandataqhp[2:39]))
require(MASS)
require(caret)
require(nnet)
Accuracies <- c(0.00)
for (i in seq(1))
{
inTrain <- createDataPartition(cqhp$metal_level, p = .80, list = FALSE)
cqhp.nn4 <- nnet(metal_level ~ ., data = cqhp, subset = inTrain, size = 4, rang = 0.5,
decay = 5e-4, maxit = 200)
Accuracies[i] <- tryCatch({
confusionMatrix(cqhp$metal_level[-inTrain], predict(cqhp.nn4, cqhp[-inTrain,], type = "class"))$overall["Accuracy"]
}, error = function(err) { Accuracies[i] <- NA })
}
qhp$issuer_name <- as.factor(qhp$issuer_name)
cleandataqhp <- qhp[c(5,24,26:62)]
dim(cleandataqhp)
cqhp <- cbind(cleandataqhp["issuer_name"], scale(cleandataqhp[2:39]))
require(MASS)
require(caret)
require(nnet)
Accuracies <- c(0.00)
for (i in seq(2))
{
inTrain <- createDataPartition(cqhp$issuer_name, p = .75, list = FALSE)
cqhp.nn4 <- nnet(issuer_name ~ ., data = cqhp, subset = inTrain, size = 4, rang = 0.5,
decay = 5e-4, maxit = 20)
Accuracies[i] <- tryCatch({
confusionMatrix(cqhp$issuer_name[-inTrain], predict(cqhp.nn4, cqhp[-inTrain,], type = "class"))$overall["Accuracy"]
}, error = function(err) { Accuracies[i] <- NA })
}
summary(Accuracies)
acclen = length(na.omit(Accuracies))
plot(density(na.omit(Accuracies)), main = paste('Neural Network accuracies:',acclen, 'runs') )
qhp$issuer_name <- as.factor(qhp$issuer_name)
cleandataqhp <- qhp[c(5,24,26:62)]
dim(cleandataqhp)
cqhp <- cbind(cleandataqhp["issuer_name"], scale(cleandataqhp[2:39]))
inTrain <- createDataPartition(cqhp$issuer_name, p = .75, list = FALSE)
cqhp.nn4 <- nnet(issuer_name ~ ., data = cqhp, subset = inTrain, size = 4, rang = 0.5,
decay = 5e-4, maxit = 20)
confusionMatrix(cqhp$issuer_name[-inTrain], predict(cqhp.nn4, cqhp[-inTrain,], type = "class"))
confusionMatrix(table(cqhp$issuer_name[-inTrain]), table(predict(cqhp.nn4, cqhp[-inTrain,])
)
)
table(cqhp$issuer_name[-inTrain])
table(predict(cqhp.nn4, cqhp[-inTrain,])
)
confusionMatrix(table(cqhp$issuer_name[-inTrain]), table(predict(cqhp.nn4, cqhp[-inTrain,])), type = "class")
table(cqhp$issuer_name[-inTrain])
predict(cqhp.nn4, cqhp[-inTrain,])
predict(cqhp.nn4, cqhp[-inTrain,])
confusionMatrix(cqhp$issuer_name[-inTrain], predict(cqhp.nn4, cqhp[-inTrain,]))
confusionMatrix(cqhp$issuer_name[-inTrain], predict(cqhp.nn4, new data = cqhp[-inTrain,]))
confusionMatrix(cqhp$issuer_name[-inTrain], predict(cqhp.nn4, newdata = cqhp[-inTrain,]))
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
# this time get ALL predictors
=======
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(5))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
pda4 <- train(PopSex ~ ., data = training, method = "pda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.lambda = 3))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
Accuracies <- c(0.00)
for (i in seq(5))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
pda4 <- train(PopSex ~ ., data = training, method = "pda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.lambda = 3))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(pda4_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
Accuracies <- c(0.00)
for (i in seq(5))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
pda4 <- train(PopSex ~ ., data = training, method = "pda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.lambda = 0))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(pda4_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
>>>>>>> c366098756d68c37760d2af766458b056d04171a
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
library(MASS)
library(caret)
Accuracies <- c(0.00)
<<<<<<< HEAD
for (i in seq(5))
=======
for (i in seq(500))
>>>>>>> c366098756d68c37760d2af766458b056d04171a
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
<<<<<<< HEAD
knn4 <- train(PopSex ~ ., data = training, method = "Linda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(knn4, list(.lambda = 3))
knn4_pred <- predict(knn4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
plot(density(Accuracies))
knn4
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
# this time get ALL predictors
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
=======
pda4 <- train(PopSex ~ ., data = training, method = "pda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.lambda = 2))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(pda4_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
plot(density(Accuracies))
pda4
confusionMatrix(pda4_pred,testing$PopSex)
confusionMatrix(pda4)
>>>>>>> c366098756d68c37760d2af766458b056d04171a
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(5))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
<<<<<<< HEAD
knn4 <- train(PopSex ~ ., data = training, method = "Linda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(knn4, list(.lambda = 3))
knn4_pred <- predict(knn4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
plot(density(Accuracies))
knn4
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
# this time get ALL predictors
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
=======
pda4 <- train(PopSex ~ ., data = training, method = "pda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.lambda = 2))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(pda4_pred,testing$PopSex)$overall["Accuracy"]
}
>>>>>>> c366098756d68c37760d2af766458b056d04171a
library(MASS)
library(caret)
Accuracies <- c(0.00)
for (i in seq(5))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
<<<<<<< HEAD
knn4 <- train(PopSex ~ ., data = training, method = "Linda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(knn4, list(.lambda = 3))
knn4_pred <- predict(knn4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
plot(density(Accuracies))
knn4
knn4 <- train(PopSex ~ ., data = training, method = "Linda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
# this time get ALL predictors
=======
pda4 <- train(PopSex ~ ., data = training, method = "pda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.lambda = 2))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(pda4_pred,testing$PopSex)$overall["Accuracy"]
}
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
>>>>>>> c366098756d68c37760d2af766458b056d04171a
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
<<<<<<< HEAD
library(MASS)
library(caret)
Accuracies <- c(0.00)
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
knn4 <- train(PopSex ~ ., data = training, method = "Linda",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
qhp <- read.csv("qhp.csv")
qhp$metal_level <- as.factor(qhp$metal_level)
cleandataqhp <- qhp[c(4,24, 26:62)]
dim(cleandataqhp)
cqhp <- cbind(cleandataqhp["metal_level"], scale(cleandataqhp[2:39]))
require(MASS)
require(caret)
require(nnet)
Accuracies <- c(0.00)
for (i in seq(1))
{
inTrain <- createDataPartition(cqhp$metal_level, p = .80, list = FALSE)
cqhp.nn4 <- nnet(metal_level ~ ., data = cqhp, subset = inTrain, size = 4, rang = 0.5,
decay = 5e-4, maxit = 20)
Accuracies[i] <- tryCatch({
confusionMatrix(cqhp$metal_level[-inTrain], predict(cqhp.nn4, cqhp[-inTrain,], type = "class"))$overall["Accuracy"]
}, error = function(err) { Accuracies[i] <- NA })
}
summary(Accuracies)
acclen = length(na.omit(Accuracies))
plot(density(na.omit(Accuracies)), main = paste('Neural Network accuracies:',acclen, 'runs') )
qhp <- read.csv("qhp.csv")
qhp$metal_level <- as.factor(qhp$metal_level)
cleandataqhp <- qhp[c(4,24, 26:62)]
dim(cleandataqhp)
cqhp <- cbind(cleandataqhp["metal_level"], scale(cleandataqhp[2:39]))
require(MASS)
require(caret)
require(nnet)
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(cqhp$metal_level, p = .80, list = FALSE)
cqhp.nn4 <- nnet(metal_level ~ ., data = cqhp, subset = inTrain, size = 4, rang = 0.5,
decay = 5e-4, maxit = 200)
Accuracies[i] <- tryCatch({
confusionMatrix(cqhp$metal_level[-inTrain], predict(cqhp.nn4, cqhp[-inTrain,], type = "class"))$overall["Accuracy"]
}, error = function(err) { Accuracies[i] <- NA })
}
summary(Accuracies)
acclen = length(na.omit(Accuracies))
plot(density(na.omit(Accuracies)), main = paste('Neural Network accuracies:',acclen, 'runs') )
=======
setwd("C:/Users/Nucleus/Desktop/Project/Advance-Analytical-Technique")
altcrime<-read.csv(altcrime.csv)
altcrime<-read.csv("altcrime.csv")
head(altcrime)
plot(as.factor(altcrime$crime)), altcrime$beat)
head(altcrime)
plot(altcrime$crime, altcrime$beat)
plot(altcrime$crime, altcrime$neighborhood)
unique(altcrime$crime)
table
table(altcrime$crime)
plot(table(altcrime$crime))
#Load libraries,
require(ggplot2)
require(animation)
require(dplyr)
#Load data
edeaths <- read.csv('altcrime.csv')
#Load the map data, set color value to -1
s = map_data('world')
install.packages("maps")
#Load libraries,
require(ggplot2)
require(animation)
require(dplyr)
#Load data
edeaths <- read.csv('altcrime.csv')
#Load the map data, set color value to -1
s = map_data('world')
s
s$colour = -1
require(ggplot2)
require(animation)
require(dplyr)
install.packages("animation")
require(ggplot2)
require(animation)
require(dplyr)
#Load data
altcrime <- read.csv('altcrime.csv')
#Load the map data, set color value to -1
s = map_data('world')
s$colour = -1
head(altcrime)
#Load data
altcrime <- read.csv('altcrime.csv')
#Load the map data, set color value to -1
s = map_data('world')
s$colour = -1
#malaria estimated  deaths
#create a list of years for use in both plots
years <- altcrime$date
head(years)
saveGIF(
for (yr in years ){
print(yr)
altcrime<-read.csv("altcrimev1.csv")
head(altcrime)
plot(altcrime$year, altcrime$neighborhood)
altcrime<-read.csv("altcrimev1.csv")
head(altcrime)
plot(altcrime$year, altcrime$neighborhood)
altcrime<-read.csv("altcrimev1.csv")
head(altcrime)
plot(altcrime$year, altcrime$neighborhood)
altcrime<-read.csv("altcrimev1.csv")
altcrime<-read.csv("altcrimev1.csv")
head(altcrime)
plot(altcrime$year, altcrime$neighborhood)
unique(altcrime$year)
>>>>>>> c366098756d68c37760d2af766458b056d04171a
